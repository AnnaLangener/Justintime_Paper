---
title: "Paper_Results"
output: html_document
date: "2025-01-20"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(randomForest)
library(dplyr)
library(lme4)
library(caret)
library(pROC)
library(patchwork)
```
## General Information
This R Markdown file can be used to replicate our results that are presented in the paper. Please note that it does not contain the shiny app.


## Pitfall 1: Within person performance Emprircal Example

```{r }
############ Table 4 #############
####### Simulation Study #########

# Basic Parameters from Study
n_features <- 10  # Features
n_samples <- 200  # Timepoints
n_subjects <- 150 # Subjects

# Generating Outcome
overall_prob_outcome <- 0.1  # Overall probability of 1 (for the entire dataset) (e.g., tracking depression 0.146)
sd_outcome <- 0.25 # Controls variability BETWEEN different subject (nneds to be smaller than sqrt(overall_prob_outcome*(1-overall_prob_outcome)))

# Generating Features
A <- 0.05 # Relationship between features and outcome
feature_std <- 0.1 # population level feature generating process
B <- 0.8  # Cross-subject variability ("random effect") (added per participants for all timepoints)
C <- 0.45 # Within-subject variability (added within participant for each timepoint)

source("Simulation_Functions_notshiny.R")

set.seed(12361488)
features_sample <- create_data(n_features,n_samples,n_subjects,A,feature_std,B,C,overall_prob_outcome,sd_outcome,0,0)
features_sample <- features_sample[[1]]

sim_1 <- run_simulation(features_sample,"row-wise",1, testsize = 0.3)
sim_2 <- run_simulation_centering(features_sample,"row-wise",1,testsize = 0.3)
sim_3 <- run_simulation(features_sample,"subject-wise",1, testsize = 0.3)
sim_4 <- run_simulation_slidingwindow(features_sample,1,windowsize = 14)

table <- rbind(sim_1$overall_summary,sim_3$overall_summary, sim_4$overall_summary)
table$'AUC Overall' <- c(sim_1$auc_value,sim_3$auc_value,sim_4$auc_value)
colnames(table) <-  c("Mean AUC within-person:", "SD AUC within-person:", "% of AUC > 0.5 within-person:", "N included within-person:", "AUC Overall")
rownames(table) <- c("row-wise","subject-wise","rolling-window")
table <- round(table[,c(5,1,2,3,4)], 2)
table
```

```{r }
############ Table 5 #############
############# Binary #############

source("Simulation_UploadData.R")
data = read.csv("esm_clean.csv")
set.seed(1234)

data = data  %>% group_by %>%
  group_by(user_id) %>%
  mutate(day = row_number())

data <- data %>%
  group_by(user_id) %>%
  filter(n_distinct(day) >= 150) %>%
  ungroup()
data = data[data$day <= 150,]

sampled_ids <- sample(unique(data$user_id), size = 20, replace = FALSE)

data <- data %>% 
  filter(user_id %in% sampled_ids)

data$user_id <- sapply(data$user_id, match, unique(unlist(data$user_id)))


id_variable = "user_id"   
time_variable = "day"

colnames(data)[colnames(data) == "user_id"] <- "subject"
colnames(data)[colnames(data) == "day"]     <- "time"
#colnames(data)[colnames(data) == "wantedToFeel_goodAboutMe"]  <- "y" 

data <- data %>%
  group_by(subject) %>%
  mutate(y = lag(wantedToFeel_goodAboutMe, n = 1)) # Lag outcome

data <- data[!is.na(data$y),]

## Run strategies
r_1 <- run_simulation_own(
  features_sample = data,
  cv              = "record-wise",
  n_bootstrap     = 1,
  testsize        = 0.3,
  n_features      =  c("feelingBadToGood", "energy", 
                       "thinkingOverAndOver", "lonely", "selfWorth", "appreciating", "stressed"),
  seed = 1234
  
)

r_3 <- run_simulation_own(
  features_sample = data,
  cv              = "subject-wise",
  n_bootstrap     = 1,
  testsize        = 0.3,
  n_features      =  c("feelingBadToGood", "energy", 
                       "thinkingOverAndOver", "lonely", "selfWorth", "appreciating", "stressed"),
  seed = 1234
  
)
r_4 <- run_simulation_slidingwindow_own(
  features_sample = data,
  n_bootstrap     = 1,
  windowsize      = 14,
  n_features      = c("feelingBadToGood", "energy",
                      "thinkingOverAndOver", "lonely", "selfWorth", "appreciating", "stressed"),
  seed = 1234
)


table <- rbind(r_1$overall_summary,r_3$overall_summary, r_4$overall_summary)
table$'AUC Overall' <- c(r_1$auc_value,r_3$auc_value,r_4$auc_value)
colnames(table) <-  c("Mean AUC within-person:", "SD AUC within-person:", "% of AUC > 0.5 within-person:", "N included within-person:", "AUC Overall")
rownames(table) <- c("row-wise","subject-wise","rolling-window")
round(table,2)
```


```{r }
############ Table 5 #############
############# Continious #########

source("Simulation_continous.R")

data = read.csv("esm_clean.csv")
set.seed(1234)

data = data  %>% group_by %>%
  group_by(user_id) %>%
  mutate(day = row_number())

data <- data %>%
  group_by(user_id) %>%
  filter(n_distinct(day) >= 150) %>%
  ungroup()
data = data[data$day <= 150,]

sampled_ids <- sample(unique(data$user_id), size = 20, replace = FALSE)

data <- data %>% 
  filter(user_id %in% sampled_ids)

data$user_id <- sapply(data$user_id, match, unique(unlist(data$user_id)))


id_variable = "user_id"   
time_variable = "day"

colnames(data)[colnames(data) == "user_id"] <- "subject"
colnames(data)[colnames(data) == "day"]     <- "time"
#colnames(data)[colnames(data) == "wantedToFeel_goodAboutMe"]  <- "y"

data <- data %>%
  group_by(subject) %>%
  mutate(y = lag(lonely, n = 1))

data <- data[!is.na(data$y),]

## Run strategies
r_1 <- run_simulation_own(
  features_sample = data,
  cv              = "record-wise",
  n_bootstrap     = 1,
  testsize        = 0.3,
  n_features      =  c("feelingBadToGood", "energy", 
                       "thinkingOverAndOver", "selfWorth", "appreciating", "stressed"),
  seed = 1234
  
)

r_3 <- run_simulation_own(
  features_sample = data,
  cv              = "subject-wise",
  n_bootstrap     = 1,
  testsize        = 0.3,
  n_features      =  c("feelingBadToGood", "energy", 
                       "thinkingOverAndOver", "selfWorth", "appreciating", "stressed"),
  seed = 1234
  
)
r_4 <- run_simulation_slidingwindow_own(
  features_sample = data,
  n_bootstrap     = 1,
  windowsize      = 14,
  n_features      = c("feelingBadToGood", "energy",
                      "thinkingOverAndOver", "selfWorth", "appreciating", "stressed"),
  seed = 1234
)

table <- rbind(
  r_1[c("rsq", "cor", "overall_summary.mean_r2", "overall_summary.mean_cor", "overall_summary.sd")],
  r_3[c("rsq", "cor", "overall_summary.mean_r2", "overall_summary.mean_cor", "overall_summary.sd")],
  r_4[c("rsq", "cor", "overall_summary.mean_r2", "overall_summary.mean_cor", "overall_summary.sd")]
)

table <- round(table[,c(5,1,2,3,4)], 2)
table
```


```{r}
############# Figure 4 #################
########################################

result <- read.csv("simulation_results_0.csv") # see Run_Simulation.R to investigate how results were created

p1 <- ggplot(result[result$A == 0,], aes(x=icc, y=auc, color = icc_pred)) + # color: icc_pred
  geom_point(alpha=0.4, size = 0.8) +
  theme_minimal() +
  scale_colour_gradientn(colours = c("#1B4332", "#40916C", "#74C69D", "#B5E48C", "#FDE68A", "#FFB5A7")) +
  ylab("Prediction Performance (Overall AUC)") +
  xlab("% of Total Variation Explained by Between Person Differences in the Outcome \n(ICC Outcome)") +
  guides(col = guide_colourbar(title = "% of Total Variation Explained by \nBetween Person Differences \nin Predictors (ICC Predictor)")) +
  ggtitle("Bias in Performance Estimates (AUC) When No Relationship Exists: Expected AUC = 0.5") +
  annotate("text", x = 0.07, y = 0.82, label =  "Greater bias when between person differences explain a \nlarger % of total variation in both outcome and predictors.",  hjust = 0) +
  geom_curve(
    aes(x = 0.2, y = 0.86, xend = 0.35, yend = 0.93), 
    arrow = arrow(length = unit(0.08, "inch")), 
    size = 0.3, 
    color = "gray20", 
    curvature = -0.2
  ) + 
  annotate("text", x = 0.38, y = 0.58, label = "Low bias if between person differences explain a small \n% of total variation in outcome, predictors, or both.",  hjust = 0) +
    geom_curve(
    aes(x = 0.37, y = 0.55, xend = 0.33, yend = 0.51), 
    arrow = arrow(length = unit(0.08, "inch")), 
    size = 0.3, 
    color = "gray20", 
    curvature = 0.1
  ) 
  # Adding a diagonal line to illustrate the linear relationship
ggsave("Figures/Figure4_Example2.jpg",
  plot = p1,
  width = 10.2,
  height = 4.5)

p1

mean(result$auc_individual[result$A == 0])
sd(result$auc_individual[result$A == 0])
mean(result$auc_c[result$A == 0])
sd(result$auc_c[result$A == 0])
sd(result$auc_individual[result$A == 0])

```

```{r}
############# Figure 5 BINARY #################
########################################
library(ggplot2)
library(tidyr)
library(dplyr)
library(patchwork)

final_results_df_2_b = read.csv("final_results_df_2_b.csv")
final_results_df_3_b = read.csv("final_results_df_3_b.csv")
final_results_df_4_b = read.csv("final_results_df_4_b.csv")
final_results_df_5_b = read.csv("final_results_df_5_b.csv")

plot_data = function(data_viz, spanpar){
  # Reshape to long format
  df_long <- data_viz %>%
    pivot_longer(
      cols = c(`shuffle_AUC.`, `movingwindowshuffle_AUC.`),
      names_to = "AUC_type",
      values_to = "AUC"
    )
  
  p = ggplot(df_long, aes(x = icc_data, y = AUC, color = AUC_type)) +
    geom_point(alpha = 0.8, size = 1) +
    geom_smooth(se = FALSE, method = "loess", span = spanpar) +
    theme_minimal() +
    scale_color_manual(
      values = c(
        "shuffle_AUC." = "#40916C",
        "movingwindowshuffle_AUC." = "#4D8FAC"
      ), 
      labels = c(
        "shuffle_AUC." = "No true Relationship (Record-Wise)",
        "movingwindowshuffle_AUC." = "No true Relationship (Moving-Window)"
      )
    ) +
    geom_hline(yintercept = 0.5, color = "grey", size = 0.8) +
    labs(color = "") +
    ylim(0.4, 0.95) +
    ggtitle(paste0("N: ", max(data_viz$num_subjects),
                   ", Timepoints: ", max(data_viz$num_samples),
                   ",\nICC Predictors (mean): ", round(data_viz$icc_pred, 2))) +
    ylab("Overall AUC") +
    xlab("ICC Outcome")
  
  return(p)
}

spanpar = 0.6

p2 = plot_data(final_results_df_2_b, spanpar)
p3 = plot_data(final_results_df_3_b, spanpar)
p4 = plot_data(final_results_df_4_b, spanpar)
p5 = plot_data(final_results_df_5_b, spanpar)

# Combine all plots and collect legends at the bottom
final_plot <- (p2 + p3 + p4 + p5) + 
  plot_layout(ncol = 2, guides = "collect") & 
  theme(legend.position = "bottom")

# Add title and optional styling
final_plot <- final_plot +
  plot_annotation(
    title = "Predictive Performance Shuffled Data Binary Outcomes",
    theme = theme(
      plot.title = element_text(size = 16, face = "bold", hjust = 0.5)
    )
  )

print(final_plot)
ggsave("Figures/Figure5_NullModelBinary.jpg",
  plot = final_plot,
  width = 7,
  height = 6)
```

```{r}
############# Figure 6 Continiuous #################
########################################
library(ggplot2)
library(tidyr)
library(dplyr)
library(patchwork)

final_results_df_2 = read.csv("final_results_df_2.csv")
final_results_df_3 = read.csv("final_results_df_3.csv")
final_results_df_4 = read.csv("final_results_df_4.csv")
final_results_df_5 = read.csv("final_results_df_5.csv")

plot_data = function(data_viz, spanpar){
  # Reshape to long format
  df_long <- data_viz %>%
    pivot_longer(
      cols = c(shuffle_cor,movingwindowshuffle_cor),
       names_to = "type",
      values_to = "Correlation"
    )
  
  p = ggplot(df_long, aes(x = icc_data, y = Correlation, color = type)) +
    geom_point(alpha = 0.8, size = 1) +
    geom_smooth(se = FALSE, method = "loess", span = spanpar) +
    theme_minimal() +
    scale_color_manual(values = c(
      "shuffle_cor" = "#40916C",
      "movingwindowshuffle_cor" = "#4D8FAC"
    ), labels = c("shuffle_cor" = "No true Relationship (Record-Wise)", 
                  "movingwindowshuffle_cor" ="No true Relationship (Moving-Window)"
    )) +
    labs(color = "") +
    ggtitle(paste0("N: ", max(data_viz$num_subjects),
                   ", Timepoints: ", max(data_viz$num_samples),
                   ",\nICC Predictors (mean): ", round(data_viz$icc_pred, 2))) +
    ylab("Overall Correlation") +
    xlab("ICC Outcome") +
    ylim(0, 0.7)
  
  return(p)
}

spanpar = 0.4

p2 = plot_data(final_results_df_2, spanpar)
p3 = plot_data(final_results_df_3, spanpar)
p4 = plot_data(final_results_df_4, spanpar)
p5 = plot_data(final_results_df_5, spanpar)

# Combine the plots and collect the legend
final_plot2 <- (p2 + p3 + p4 + p5) +
  plot_layout(ncol = 2, guides = "collect") & 
  theme(legend.position = "bottom")

# Add title and optional styling
final_plot2 <- final_plot2 +
  plot_annotation(
    title = "Predictive Performance Shuffled Data Continuous Outcomes",
    theme = theme(
      plot.title = element_text(size = 16, face = "bold", hjust = 0.5)
    )
  )

print(final_plot2)
ggsave("Figures/Figure6_NullModelContinious.jpg",
  plot = final_plot2,
  width = 7,
  height = 6)

```


## Pitfall 2: Mismatch between chosen cross-validation strategy, employment, and actual observations 
```{r }
############ Figure 7 #############
##################################

# Generating Outcome
overall_prob_outcome <- 0.1  # Overall probability of 1 (for the entire dataset) (e.g., tracking depression 0.146)
sd_outcome <- 0.2 # Controls variability BETWEEN different subject (nneds to be smaller than sqrt(overall_prob_outcome*(1-overall_prob_outcome)))

# Generating Features
A <- 0.05 # Relationship between features and outcome
feature_std <- 0.1 # population level feature generating process
B <- 0.8  # Cross-subject variability ("random effect") (added per participants for all timepoints)
C <- 0.45 # Within-subject variability (added within participant for each timepoint)

source("Simulation_Functions_notshiny.R")

set.seed(12361488)
features_sample <- create_data(n_features,90,150,A,feature_std,B,C,overall_prob_outcome,sd_outcome,0,0)

# Merge the p-values with the original dataset for plotting
data <- features_sample[[2]] 

# Compute mean y for each subject and reorder factor levels in ascending order
subject_stats <- data %>%
  group_by(subject) %>%
  summarize(mean_y = mean(y, na.rm = TRUE),
            has_y1 = any(y == 1)) %>%  # Identify if subject has any y = 1
  arrange(mean_y)  

# Convert subject to a factor with the same levels as in data
subject_stats$subject <- factor(subject_stats$subject, levels = subject_stats$subject)

# Count the number of subjects with at least one y = 1
num_subjects_with_y1 <- sum(subject_stats$has_y1)

# Apply the new factor levels to data
data <- data %>%
  mutate(subject = factor(subject, levels = subject_stats$subject))

# Merge "has_y1" information into the main dataset
data <- left_join(data, subject_stats, by = "subject")

# Create the sorted plot with conditional background color
p2 <- ggplot(data, aes(x = time, y = y)) +
  # Add background shading for subjects with y = 1
  geom_rect(
    data = data %>% filter(!has_y1),
    aes(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf),
    fill = "#E5E4E2", alpha = 0.05, inherit.aes = T
  ) +
  geom_point(color = "#FC9D9A", size = 0.5) +                       
  facet_wrap(~subject) +               
  labs(
    x = "Time", 
    y = "Outcome", 
    title = paste("Within-person variability over time: \n78 participants (52%) do not experience within-person variability. ")
  ) +
  scale_y_continuous(breaks = c(0, 1)) +  # Ensure only 0 and 1 appear on the y-axis
  theme_minimal() +
  theme(axis.text.x=element_blank(),axis.ticks.x=element_blank()) +
  guides(fill = "none") 

p2

# ggsave( "Figures/Figure7_Example_var.jpg",
#   plot = p2,
#   width = 8,
#   height = 7)

```


## Pitfall 3: Weak benchmark and missing baseline comparison

```{r }
############ Table 7 #############
##################################
sim_1$auc_value_base # row-wise
sim_4$auc_value_base # rolling window


sim_4$auc_value


test <- sim_4$ind_base[[1]] %>%
  group_by(subject) %>%
  filter(length(unique(true)) > 1) %>%
  filter(sum(true == 1) > 0, sum(true == 0) > 0) %>%
  summarise(
    auc_val = pROC::auc(pROC::roc(as.numeric(as.character(true)), as.numeric(as.character(pred)), quiet = TRUE))[1],
    .groups = "drop" # Ungroup after summarizing
  )

mean(test$auc_val)

```

```{r}
############# Figure 9 BINARY #################
########################################
library(ggplot2)
library(tidyr)
library(dplyr)
library(patchwork)

final_results_df_2_b = read.csv("final_results_df_2_b.csv")
final_results_df_3_b = read.csv("final_results_df_3_b.csv")
final_results_df_4_b = read.csv("final_results_df_4_b.csv")
final_results_df_5_b = read.csv("final_results_df_5_b.csv")

plot_data = function(data_viz,spanpar){
  # Reshape to long format
  df_long <- data_viz %>%
    pivot_longer(
      cols = c(`real_AUC.random.intercept.only.`, `real_AUC.`,`movingwindow_AUC.`,`subjectwise_AUC.`,`movingwindow_AUC.random.intercept.only.`),
      names_to = "AUC_type",
      values_to = "AUC"
    )
  p = ggplot(df_long, aes(x = icc_data, y = AUC, color = AUC_type)) +
    geom_point(alpha = 0.8, size = 1) +
    geom_smooth(se = FALSE, method = "loess",span = spanpar) +
    theme_minimal() +
    scale_color_manual(values = c(
      "real_AUC.random.intercept.only." ="#B5E48C" ,
      "real_AUC." = "#74C69D",
      "movingwindow_AUC." ="#9EC5E7",
      "movingwindow_AUC.random.intercept.only." = "#A2D2FF",
      "subjectwise_AUC." ="#FFB5A7"
    ), 
    labels = c(
               "real_AUC.random.intercept.only."="Random Intercept only (Record-Wise)",
               "real_AUC." ="Random Forest (Record-Wise) ",
               "movingwindow_AUC." ="Random Forest (Moving-Window)",
               "subjectwise_AUC." ="Random Forest (Subject-Wise)",
               "movingwindow_AUC.random.intercept.only." = "Random Intercept only (Moving-Window)")) +
    theme(legend.position = "none") +
    geom_hline(yintercept = 0.5, color = "grey", size = 0.8) +
    labs(color = "Model") +
    ylim(0.4,0.95) +
    ggtitle(paste0("N: ", max(data_viz$num_subjects),", ", "Timepoints: ", max(data_viz$num_samples),", ","\n",  "ICC Predictors (mean): ", round(data_viz$icc_pred,2))) +
    ylab("Overall AUC") +
    xlab("ICC Outcome")
  return(p)
}

spanpar = 0.6

p2 = plot_data(final_results_df_2_b, spanpar)
p3 = plot_data(final_results_df_3_b, spanpar)
p4 = plot_data(final_results_df_4_b, spanpar)
p5 = plot_data(final_results_df_5_b, spanpar)

# Combine all plots and collect legends at the bottom
final_plot <- (p2 + p3 + p4 + p5) + 
  plot_layout(ncol = 2, guides = "collect") & 
  theme(legend.position = "right")

# Add title and optional styling
final_plot <- final_plot +
  plot_annotation(
    title = "Predictive Performance Baseline Comparison Binary Outcomes",
    theme = theme(
      plot.title = element_text(size = 16, face = "bold", hjust = 0.5)
    )
  )

print(final_plot)
ggsave("Figures/Figure9_BaselineBinary.jpg",
  plot = final_plot,
  width = 9,
  height = 8)
```

```{r}
############# Figure 10 Continiuous #################
########################################
library(ggplot2)
library(tidyr)
library(dplyr)
library(patchwork)

final_results_df_2 = read.csv("final_results_df_2.csv")
final_results_df_3 = read.csv("final_results_df_3.csv")
final_results_df_4 = read.csv("final_results_df_4.csv")
final_results_df_5 = read.csv("final_results_df_5.csv")

plot_data = function(data_viz,spanpar){
  # Reshape to long format
  df_long <- data_viz %>%
    pivot_longer(
    #  cols = c(`shuffle_mae`, `real_mae_base`, `real_mae`,`centered_mae`,`subjectwise_mae`),
      cols = c(`real_cor_base`, `real_cor`,`movingwindow_cor`,`subjectwise_cor`,movingwindow_cor_base),
      names_to = "type",
      values_to = "Correlation"
    )
  p = ggplot(df_long, aes(x = icc_data, y = Correlation, color = type)) +
    geom_point(alpha = 0.8, size = 1) +
    geom_smooth(se = FALSE, method = "loess",span = spanpar) +
    theme_minimal() +
    scale_color_manual(values = c(
      "real_cor_base" ="#B5E48C" ,
      "real_cor" = "#74C69D",
      "movingwindow_cor" = "#9EC5E7",
      "movingwindow_cor_base" = "#A2D2FF",
      "subjectwise_cor" ="#FFB5A7"
    ), labels = c("real_cor_base"="Random Intercept only (Record-Wise)",
                  "real_cor" ="Random Forest (Record-Wise)",
                  "movingwindow_cor" ="Random Forest (Moving-Window) ",
                  "subjectwise_cor" = "Random Forest (Subject-Wise)",
                  "movingwindow_cor_base" = "Random Intercept only (Moving-Window)"
    )) +
    theme(legend.position = "none") +
    labs(color = "Model") +
   # xlim(0.1,1) +
    ggtitle(paste0("N: ", max(data_viz$num_subjects),", ", "Timepoints: ", max(data_viz$num_samples),", ","\n",  "ICC Predictors (mean): ", round(data_viz$icc_pred,2))) +
    ylab("Overall Correlation") +
    xlab("ICC Outcome") +
    ylim(0, 1)
  return(p)
}


spanpar = 0.4

p2 = plot_data(final_results_df_2, spanpar)
p3 = plot_data(final_results_df_3, spanpar)
p4 = plot_data(final_results_df_4, spanpar)
p5 = plot_data(final_results_df_5, spanpar)

# Combine all plots and collect legends at the bottom
final_plot <- (p2 + p3 + p4 + p5) + 
  plot_layout(ncol = 2, guides = "collect") & 
  theme(legend.position = "right")

# Add title and optional styling
final_plot <- final_plot +
  plot_annotation(
    title = "Predictive Performance Baseline Comparison Continuous Outcomes",
    theme = theme(
      plot.title = element_text(size = 16, face = "bold", hjust = 0.5)
    )
  )

print(final_plot)
ggsave("Figures/Figure10_BaselineContinious.jpg",
  plot = final_plot,
  width = 9,
  height = 8)

```

```{r }
############ Figure 8 #############
##################################

result = read.csv("simulation_results_baseline.csv")
p7 <- ggplot(result, aes(x=icc, y=auc_value_base)) +
  geom_point(alpha=0.5, size = 1.2, color = "#40916C") +
  #scale_size(range = c(.001, 6), name="") +
  theme_minimal() +
  scale_colour_gradientn(colours = c("#40916C")) +
  ylab("Overall Performance (AUC)") +
  xlab("% of Total Variation Explained by Between Person Differences in the Outcome (ICC Outcome)") +
  guides(col = guide_colourbar()) +
  ggtitle(paste("Performance of a Random Intercept Only Model (No Predictors Included)")) +
  geom_hline(yintercept = 0.5) +
  ylim(range= c(0.5,1)) +
    annotate("text", x = 0.5, y = 0.82, label =  "Performance increases as between person differences explain a \nlarger % of total variation in the outcome",  hjust = 0) +
  geom_curve(
    aes(x = 0.7, y = 0.85, xend = 0.5, yend = 0.91), 
    arrow = arrow(length = unit(0.08, "inch")), 
    size = 0.3, 
    color = "#1B4332", 
    curvature = 0.2
  ) +
      annotate("text", x = 0.2, y = 0.62, label =  "Performance can be moderate even if between person differences explain only a relatively \nsmall % of total variation in the outcome",  hjust = 0) +
  geom_curve(
    aes(x = 0.19, y = 0.62, xend = 0.07, yend = 0.61), 
    arrow = arrow(length = unit(0.08, "inch")), 
    size = 0.3, 
    color = "#1B4332", 
    curvature = 0.2
  ) 

ggsave(  "Figures/Figure8.jpg",
  plot = p7,
  width = 10,
  height = 5)

```


Other things that were not presented in the paper (but used for a presentation):




```{r }
## Try out

# Basic Parameters from Study
n_features <- 10  # Features
n_samples <- 200  # Timepoints
n_subjects <- 15 # Subjects

# Generating Outcome
overall_prob_outcome <- 0.4  # Overall probability of 1 (for the entire dataset) (e.g., tracking depression 0.146)
sd_outcome <- 0.3 # Controls variability BETWEEN different subject (nneds to be smaller than sqrt(overall_prob_outcome*(1-overall_prob_outcome)))

# Generating Features
A <- 0.02 # Relationship between features and outcome
feature_std <- 0.1 # population level feature generating process
B <- 0.8  # Cross-subject variability ("random effect") (added per participants for all timepoints)
C <- 0.2 # Within-subject variability (added within participant for each timepoint)

source("Simulation_Functions_notshiny.R")

set.seed(12361488)
features_sample <- create_data(n_features, n_samples, n_subjects, A, feature_std, B, C, overall_prob_outcome, sd_outcome, 0,0)

features_sample <- features_sample[[1]]

sim_1 <- run_simulation(features_sample,"row-wise",1, testsize = 0.3)

table <- rbind(sim_1$overall_summary)
table$'AUC Overall' <- c(sim_1$auc_value)

table

library(dplyr)
library(ggplot2)

pred_true = as.data.frame(sim_1$ind)



pred_true <- pred_true %>%
  arrange(subject, true) %>%
  group_by(subject) %>%
  mutate(day = row_number())


library(pROC)
library(dplyr)

# Compute individual AUC
ind_auc <- pred_true %>%
  group_by(subject) %>%
  filter(length(unique(true)) > 1) %>%
  filter(sum(true == 1) > 0, sum(true == 0) > 0) %>%
  summarise(
    auc_val = pROC::auc(pROC::roc(response = true, predictor = pred, direction = "<",positive = "1", levels = c(0,1)))[1],
    .groups = "drop"
  )

# Merge AUCs back into pred_true
pred_true <- left_join(pred_true, ind_auc, by = "subject")
pred_true$auc_val = round(pred_true$auc_val,2)
pred_true$auc_val[is.na(pred_true$auc_val)] = "-"

pred_true$pred  = ifelse(pred_true$pred  > 0.5, 1, 0)



# Add prediction correctness column
pred_true <- pred_true %>%
  mutate(prediction_correct = ifelse(true == pred, "Correct", "Incorrect")) # CHECK AGAIN IF PREDICTION IS 0/1 !!!


plot = ggplot(pred_true, aes(day, subject, color = factor(true), shape = prediction_correct)) + 
  geom_point(size = 2, alpha = 0.8) +
  geom_text(aes(label = ifelse(!duplicated(subject), paste("AUC: ", auc_val), "")),
            x = -Inf, hjust = 0, size = 3, color = "gray40") +  # AUC on the left side
  scale_color_manual(values = c("0" = "#FFB5A7", "1" = "#40916C")) +
  scale_shape_manual(values = c("Correct" = 15, "Incorrect" = 0)) +
  labs(color = NULL, shape = NULL) +  # Removes legend titles
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    legend.position = "bottom",
    axis.text.y = element_blank(),
    axis.text.x = element_blank()     # Removes x-axis tick labels
  ) +
  xlim(-6, 75) +
  labs(y = paste0("Within-Person"), x = "") +
  ggtitle(paste("AUC evaluated over the whole dataset:", round(table$'AUC Overall', 2), "(Between-Person)")) +
  theme(text = element_text('Futura'),axis.title=element_text(size=14)) 
plot
# ggsave("WithinBetween_Example.png", 
#        width = 6100, height = 3000, units = "px", dpi = 800,plot = plot)


```